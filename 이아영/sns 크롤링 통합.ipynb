{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc68e3ea",
   "metadata": {},
   "source": [
    "# 크롤러 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb551094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By \n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import os, sys\n",
    "import tweepy\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2e827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/chromedriver_win32/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253f9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub('[^ ㄱ-ㅣ가-힣]+',' ',text)\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74106d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = 'C:/Users/dkdud/Untitled Folder/api_key.json'\n",
    "with open(key_path,'r') as f:\n",
    "    key = json.load(f)\n",
    "\n",
    "# 개인정보 인증을 요청하는 Handler입니다.\n",
    "auth = tweepy.OAuthHandler(key['CONSUMER_KEY'], key['CONSUMER_SECRET'])\n",
    "\n",
    "# 인증 요청을 수행합니다.\n",
    "auth.set_access_token(key['ACCESS_TOKEN_KEY'], key['ACCESS_TOKEN_SECRET'])\n",
    "\n",
    "# twitter API를 사용하기 위한 준비입니다.\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05657c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인스타 게시물을 불러오기 위한 사전작업 단계\n",
    "driver.get('https://www.instagram.com/')\n",
    "p_tag = WebDriverWait(driver, timeout =5).until(EC.presence_of_element_located((By.TAG_NAME, \"P\")))\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#인스타그램 로그인을 위한 계정정보\n",
    "email='data.campuss'\n",
    "input_id = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[0]\n",
    "input_id.clear()\n",
    "input_id.send_keys(email)\n",
    "\n",
    "password = 'data.2021'\n",
    "input_pw = driver.find_elements_by_css_selector('input._2hvTZ.pexuQ.zyHYP')[1]\n",
    "input_pw.clear()\n",
    "input_pw.send_keys(password)\n",
    "input_pw.submit()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "driver.find_element_by_css_selector('button.sqdOP.yWX7d.y3zKF').click()\n",
    "time.sleep(3)\n",
    "driver.find_element_by_css_selector('button.aOOlW.HoLwm').click()\n",
    "time.sleep(3)\n",
    "\n",
    "def insta_searching(word):\n",
    "    url ='https://www.instagram.com/explore/tags/' + str(word)\n",
    "    return url\n",
    "\n",
    "def click_first(driver):\n",
    "    first =driver.find_element_by_css_selector('div._9AhH0')\n",
    "    first.click()\n",
    "    time.sleep(7)\n",
    "    \n",
    "def next_page(driver):\n",
    "    next_page = driver.find_element_by_css_selector('body > div._2dDPU.CkGkG > div.EfHg9 > div > div > a._65Bje.coreSpriteRightPaginationArrow')\n",
    "    next_page.click()\n",
    "    time.sleep(7)\n",
    "\n",
    "    \n",
    "def get_content(driver):\n",
    "    \n",
    "# 1. 현재 페이지의 HTML 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    tag_list =[]\n",
    "# 2. 본문내용\n",
    "    try:\n",
    "        content = soup.select('div.C4VMK > span')[0].text\n",
    "    except:\n",
    "        content = ''\n",
    "# 3. 본문 내용에서 해시태그 가져오기(정규표현식 활용)\n",
    "    tags = re.findall('#[A-Za-z0-9가-힣]+', content)\n",
    "    tag = ''.join(tags).replace(\"#\",\" \") # \"#\" 제거\n",
    "    tag_data = tag.split()\n",
    "    for tag_one in tag_data:\n",
    "        tag_list.append(tag_one)\n",
    "        \n",
    "    data = [content, tag_data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f98ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insta_crawling(driver,keyword, target):\n",
    "    \n",
    "    result_list =[]\n",
    "    url = insta_searching(keyword)\n",
    "    driver.implicitly_wait(2)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    click_first(driver)\n",
    "\n",
    "    for i in range(target):\n",
    "        try:\n",
    "            result_list.append(get_content(driver))\n",
    "            next_page(driver)\n",
    "        except:\n",
    "            time.sleep(2)\n",
    "            next_page(driver)\n",
    "    df=pd.DataFrame(result_list)\n",
    "    df.columns=['본문','해시태그']\n",
    "    df['본문'] = df['본문'].apply(lambda x : clean_text(x))\n",
    "    df['해시태그'] = df['해시태그'].apply(lambda x : str(x))\n",
    "    df['해시태그'] = df['해시태그'].apply(lambda x : clean_text(x))\n",
    "    df['본문']= df['본문'] + df['해시태그']\n",
    "    df.drop(['해시태그'],axis=1,inplace=True)\n",
    "    df = df.drop_duplicates(subset=['본문'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c12007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#트위터 게시물 가져오는 단계\n",
    "def twitter_crawling(keyword):\n",
    "    columns = ['본문']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    max_tweets = 1000\n",
    "    searched_tweets = [status for status in tweepy.Cursor(api.search, q=keyword).items(max_tweets)]\n",
    "\n",
    "    for tweet in searched_tweets:\n",
    "        tweet_json = tweet._json\n",
    "        tweet_text = tweet_json['text']\n",
    "        row = [tweet_text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df = df.append(series, ignore_index=True)\n",
    "\n",
    "    df['본문'] = df['본문'].apply(lambda x : clean_text(x))\n",
    "    df = df.drop_duplicates(subset=['본문'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c976887",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = '환경오염'\n",
    "target = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a23953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insta_df = insta_crawling(driver,keyword, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c2a0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = twitter_crawling(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "371438ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns_df = pd.concat([twitter_df, insta_df],join='outer',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe28cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_df.to_csv('환경.csv',encoding='UTF-8-SIG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e15d8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= []\n",
    "for x in range(0,256):\n",
    "    try:\n",
    "        tp = sns_df['본문'][x]\n",
    "        tp = tp.split('.')\n",
    "    except:\n",
    "        print(\"0\")\n",
    "    text.append(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22511aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "text=list(itertools.chain(*text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8141a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm_notebook\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "80fb07a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>본문</th>\n",
       "      <th>명사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>모든 남자아이돌 옷장과 협찬에서 비니와 벙거지를 없애주세요 환경오염입니다 지구야미안해</td>\n",
       "      <td>[모든, 남자, 아이돌, 옷장, 협찬, 비니, 벙거지, 환경오염, 지구]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쓰레기를 버리지말자는 주장에 환경오염과 환경미화원의 노고를 생각하면 옳은비판이었다고...</td>\n",
       "      <td>[쓰레기, 주장, 환경오염, 환경미화원, 노고, 생각, 비판, 논쟁, 종료, 사람,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>환경오염때문에 온거면 환경주제도꺼낼수잇어요</td>\n",
       "      <td>[환경오염, 때문, 환경, 주제]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그래서 쓰레기를 무단투기하지 말라는 주장이 타집단에서 나오면 그게 옳다고 동의하는게...</td>\n",
       "      <td>[쓰레기, 무단, 투기, 말, 주장, 집단, 그게, 동의, 쓰레기, 무단, 투기, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>공룡행성에서 왜왓어요 환경오염때문인가요</td>\n",
       "      <td>[공룡, 행성, 왜왓어, 환경오염, 때문]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>도가 넘는 고열에도 타지 않고자연분해 되는데 무려 년 이 걸리는쌓여만가던 젤 아이스...</td>\n",
       "      <td>[도, 고열, 타지, 자연, 분해, 무려, 년, 이, 젤, 아이스팩, 이제, 고민,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>바다 바라 바래 보다 프로젝트리서치트립 기록 월 저녁무렵 바다 바라 바래 보다 프로...</td>\n",
       "      <td>[바다, 바, 프로젝트, 리, 치트, 립, 기록, 월, 저녁, 무렵, 바다, 바, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>우리는 끝도 없는 쓰레기라는 팬데믹에 직면했습니다 갈수록 늘어나는 쓰레기 때문에 매...</td>\n",
       "      <td>[우리, 끝, 쓰레기, 팬데믹, 직면, 갈수록, 쓰레기, 때문, 매립, 포화상태, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>한살림자주모임 한살림경기동부식생활양성과정 함께 했던 경기동부분들과 한달에 한번 지속...</td>\n",
       "      <td>[한살림, 자주, 모임, 한살림, 경기, 동부, 식생활, 양성, 과정, 동부, 달,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>환경오염 지구를살리자 한국에너지공단 적정온도 촬영한브랜드 선도애기부나눔마켓 기부와나...</td>\n",
       "      <td>[환경오염, 지구, 한국, 에너지, 공단, 적정, 온도, 촬영, 브랜드, 선도, 애...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    본문  \\\n",
       "0      모든 남자아이돌 옷장과 협찬에서 비니와 벙거지를 없애주세요 환경오염입니다 지구야미안해   \n",
       "1    쓰레기를 버리지말자는 주장에 환경오염과 환경미화원의 노고를 생각하면 옳은비판이었다고...   \n",
       "2                              환경오염때문에 온거면 환경주제도꺼낼수잇어요   \n",
       "3    그래서 쓰레기를 무단투기하지 말라는 주장이 타집단에서 나오면 그게 옳다고 동의하는게...   \n",
       "4                                공룡행성에서 왜왓어요 환경오염때문인가요   \n",
       "..                                                 ...   \n",
       "368  도가 넘는 고열에도 타지 않고자연분해 되는데 무려 년 이 걸리는쌓여만가던 젤 아이스...   \n",
       "369  바다 바라 바래 보다 프로젝트리서치트립 기록 월 저녁무렵 바다 바라 바래 보다 프로...   \n",
       "370  우리는 끝도 없는 쓰레기라는 팬데믹에 직면했습니다 갈수록 늘어나는 쓰레기 때문에 매...   \n",
       "371  한살림자주모임 한살림경기동부식생활양성과정 함께 했던 경기동부분들과 한달에 한번 지속...   \n",
       "372  환경오염 지구를살리자 한국에너지공단 적정온도 촬영한브랜드 선도애기부나눔마켓 기부와나...   \n",
       "\n",
       "                                                    명사  \n",
       "0             [모든, 남자, 아이돌, 옷장, 협찬, 비니, 벙거지, 환경오염, 지구]  \n",
       "1    [쓰레기, 주장, 환경오염, 환경미화원, 노고, 생각, 비판, 논쟁, 종료, 사람,...  \n",
       "2                                   [환경오염, 때문, 환경, 주제]  \n",
       "3    [쓰레기, 무단, 투기, 말, 주장, 집단, 그게, 동의, 쓰레기, 무단, 투기, ...  \n",
       "4                              [공룡, 행성, 왜왓어, 환경오염, 때문]  \n",
       "..                                                 ...  \n",
       "368  [도, 고열, 타지, 자연, 분해, 무려, 년, 이, 젤, 아이스팩, 이제, 고민,...  \n",
       "369  [바다, 바, 프로젝트, 리, 치트, 립, 기록, 월, 저녁, 무렵, 바다, 바, ...  \n",
       "370  [우리, 끝, 쓰레기, 팬데믹, 직면, 갈수록, 쓰레기, 때문, 매립, 포화상태, ...  \n",
       "371  [한살림, 자주, 모임, 한살림, 경기, 동부, 식생활, 양성, 과정, 동부, 달,...  \n",
       "372  [환경오염, 지구, 한국, 에너지, 공단, 적정, 온도, 촬영, 브랜드, 선도, 애...  \n",
       "\n",
       "[373 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('환경오염 크롤링.csv',encoding='UTF-8-SIG', index_col=0)\n",
    "data = data.dropna()\n",
    "\n",
    "okt = Okt()\n",
    "noun_list =[]\n",
    "for content in data['본문']:\n",
    "    nouns = okt.nouns(content)\n",
    "    noun_list. append(nouns)\n",
    "\n",
    "data['명사'] = noun_list\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31e73376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('환경오염크롤링중.csv',encoding='UTF-8-SIG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d26942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sns_df,columns=['본문'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "937555d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = df[df['본문']==\"\"].index\n",
    "df.drop(drop_index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29c01696",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-839d907ef81d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mpos_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mtemp_str\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'XSA+EC+VX+EC+VX+ETM'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-839d907ef81d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mpos_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mtemp_str\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mpos_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eunjeon\\_mecab.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, flatten)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 return [parse(self.tagger.parse(eojeol).decode('utf-8'))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eunjeon\\_mecab.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(result, allattrs)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from eunjeon import Mecab\n",
    "tokenizer = Mecab()\n",
    "pos_temp = {}\n",
    "pos_list = []\n",
    "\n",
    "for i in df['본문']:\n",
    "    temp_str = ''\n",
    "    try:\n",
    "        for j in range(len(tokenizer.pos(i))):\n",
    "            pos_temp[tokenizer.pos(i)[j][1]]+=1\n",
    "            temp_str+=tokenizer.pos(i)[j][1]+\"/\"\n",
    "    except:\n",
    "        for j in range(len(tokenizer.pos(i))):\n",
    "            pos_temp[tokenizer.pos(i)[j][1]]=1\n",
    "            temp_str+=tokenizer.pos(i)[j][1]+\"/\"\n",
    "    pos_list.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfa2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
